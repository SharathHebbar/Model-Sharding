{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30646,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install sentencepiece accelerate","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-02-06T15:48:53.036582Z","iopub.execute_input":"2024-02-06T15:48:53.037090Z","iopub.status.idle":"2024-02-06T15:49:10.415016Z","shell.execute_reply.started":"2024-02-06T15:48:53.037045Z","shell.execute_reply":"2024-02-06T15:49:10.413428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoTokenizer, AutoModelForCausalLM\nfrom accelerate import Accelerator, load_checkpoint_and_dispatch\n","metadata":{"execution":{"iopub.status.busy":"2024-02-16T16:18:39.069061Z","iopub.execute_input":"2024-02-16T16:18:39.069493Z","iopub.status.idle":"2024-02-16T16:18:46.920586Z","shell.execute_reply.started":"2024-02-16T16:18:39.069457Z","shell.execute_reply":"2024-02-16T16:18:46.919139Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel_name = \"mistralai/Mistral-7B-v0.1\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-16T16:11:11.294044Z","iopub.execute_input":"2024-02-16T16:11:11.294612Z","iopub.status.idle":"2024-02-16T16:15:22.439827Z","shell.execute_reply.started":"2024-02-16T16:11:11.294560Z","shell.execute_reply":"2024-02-16T16:15:22.438967Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/967 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b2d7f67891a54cc8b465933186ab2b0d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2ba01f8634234e3b9993fa5e462c656a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"35a4bd1dd45044d180dfe450fee8bd80"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/72.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a806a45214c4b8b8d4317406b827981"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4762facc08d34b84963847df9b55a194"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors.index.json:   0%|          | 0.00/25.1k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2f84d8d5b831489095868e56e05fa8cd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3a80c9f9a4ac4db5b13d730326198793"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00001-of-00002.safetensors:   0%|          | 0.00/9.94G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1a606ec3d34440aeaac5dff0345e7465"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model-00002-of-00002.safetensors:   0%|          | 0.00/4.54G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a6d1091bc4c54d838ffc156bce38abb2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f8d740bb9a7a43db928002ff053095b1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a70efdf89ee54973865f35a382d7b0ea"}},"metadata":{}},{"name":"stdout","text":"CPU times: user 34.4 s, sys: 59.5 s, total: 1min 33s\nWall time: 4min 11s\n","output_type":"stream"}]},{"cell_type":"code","source":"%%time\nmodel_name = \"tiiuae/falcon-7b-instruct\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-06T15:49:18.814773Z","iopub.execute_input":"2024-02-06T15:49:18.815529Z","iopub.status.idle":"2024-02-06T15:51:42.383894Z","shell.execute_reply.started":"2024-02-06T15:49:18.815494Z","shell.execute_reply":"2024-02-06T15:51:42.381519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"save_directory=\"/content/model\"\nmodel.save_pretrained(save_directory, max_shard_size=\"100MB\")","metadata":{"execution":{"iopub.status.busy":"2024-02-06T15:51:42.386416Z","iopub.execute_input":"2024-02-06T15:51:42.386972Z","iopub.status.idle":"2024-02-06T15:52:38.656095Z","shell.execute_reply.started":"2024-02-06T15:51:42.386924Z","shell.execute_reply":"2024-02-06T15:52:38.654793Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\naccelerator = Accelerator()\n\naccelerator.save_model(\n    model=model,\n    save_directory=save_directory,\n    max_shard_size=\"200MB\"\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device_map={\"\":'cpu'}\n\nmodel = load_checkpoint_and_dispatch(\n    model,\n    checkpoint=\"/content/model/\",\n    device_map=device_map,\n    no_split_module_classes=[\"Block\"]\n)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"new_model = f\"Sharathhebbar24/{model_name.split('/')[1]}_sharded\"\nnew_model","metadata":{"execution":{"iopub.status.busy":"2024-02-06T15:53:07.632889Z","iopub.execute_input":"2024-02-06T15:53:07.633457Z","iopub.status.idle":"2024-02-06T15:53:07.639876Z","shell.execute_reply.started":"2024-02-06T15:53:07.633416Z","shell.execute_reply":"2024-02-06T15:53:07.638352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"HF_TOKEN = \"<HF_TOKEN>\"","metadata":{"execution":{"iopub.status.busy":"2024-02-06T15:53:43.218491Z","iopub.execute_input":"2024-02-06T15:53:43.218915Z","iopub.status.idle":"2024-02-06T15:53:43.224238Z","shell.execute_reply.started":"2024-02-06T15:53:43.218868Z","shell.execute_reply":"2024-02-06T15:53:43.223269Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenizer.push_to_hub(\n    new_model,\n    token=HF_TOKEN\n)\n\nmodel.push_to_hub(\n    new_model,\n    token=HF_TOKEN\n)","metadata":{"execution":{"iopub.status.busy":"2024-02-06T15:53:44.711661Z","iopub.execute_input":"2024-02-06T15:53:44.712151Z","iopub.status.idle":"2024-02-06T15:59:02.218611Z","shell.execute_reply.started":"2024-02-06T15:53:44.712118Z","shell.execute_reply":"2024-02-06T15:59:02.216660Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"%%time\nmodel_name = \"Sharathhebbar24/falcon-7b-instruct_sharded\"\n\ntokenizer = AutoTokenizer.from_pretrained(model_name)\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    low_cpu_mem_usage=True,\n    torch_dtype=torch.float16\n)","metadata":{},"execution_count":null,"outputs":[]}]}